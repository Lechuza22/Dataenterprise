import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import seaborn.objects as so
import folium
import statsmodels.api as sm
import plotly.express as px
import calendar
from streamlit_folium import st_folium
from datetime import datetime
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import RandomForestRegressor, IsolationForest
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import Ridge
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from sklearn.linear_model import HuberRegressor
from sklearn.neighbors import NearestNeighbors

# -----------------------------
# CONFIGURACION INICIAL
# -----------------------------
st.set_page_config(page_title="üìä DataEnterprise", page_icon="üè¢", layout="wide")

# -----------------------------
# LOGIN SIMPLE CON SESSION_STATE
# -----------------------------
# Inicializamos el estado de autenticaci√≥n si no existe
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

# Si no est√° autenticado, mostrar input de contrase√±a
if not st.session_state.authenticated:
    st.title("üìä DataEnterprise")
    password = st.text_input("üîê Ingres√° la clave para acceder a la app:", type="password")
    if password == st.secrets["acceso"]["clave"]:
        st.session_state.authenticated = True
        st.success("Acceso concedido ‚úÖ")
    elif password != "":
        st.error("Clave incorrecta ‚ùå")

# Si est√° autenticado, mostrar la app completa
if st.session_state.authenticated:
    st.title("üìä DataEnterprise")

    # -----------------------------
    # MENU PRINCIPAL
    # -----------------------------
    menu = st.sidebar.selectbox("üìÇ Secciones", [
        "Inicio",
        "An√°lisis exploratorio",
        "An√°lisis cruzado",
        "Modelos de ML",
        "Mapa de sucursales y empleados"
    ])

    st.sidebar.markdown("---")
    st.sidebar.markdown("üë§ Usuario: Admin")

    # -----------------------------
    # CONTENIDO POR SECCION
    # -----------------------------
    if menu == "Inicio":
        st.header("üìä DataEnterprise - Proyecto de An√°lisis de Datos Empresariales")
        st.markdown("Bienvenido al panel interactivo de an√°lisis, exploraci√≥n y predicci√≥n.")
        st.markdown("Us√° el men√∫ de la izquierda para navegar por las secciones.")

    elif menu == "An√°lisis exploratorio":
        st.header("üìà An√°lisis exploratorio de datos (EDA)")

        dataset_opcion = st.selectbox("Seleccion√° el dataset a explorar:", [
            "Clientes", "Compras", "Empleados", "Gastos", "Productos", "Proveedores", "Sucursales", "Ventas"
        ])

        if dataset_opcion == "Clientes":
            st.subheader("üßç‚Äç‚ôÇÔ∏è Exploraci√≥n de Clientes")
            st.markdown("‚úÖ Conclusiones preliminares del an√°lisis del dataset Clientes: - Edad promedio de los clientes es de 40 a√±os, con una alta concentraci√≥n entre los 25 y 55.\n- Hay una clara concentraci√≥n geogr√°fica en el AMBA, especialmente Ciudad de Buenos Aires.\n- El 100% de los clientes est√°n activos (no hay marca de baja).\n- La diversidad de localidades es grande (527), pero unas pocas concentran la mayor√≠a.\n- La base de clientes parece limpia y homog√©nea, con pocos outliers.")

            df_clientes = pd.read_csv("Clientes_transformados.csv")

            # Histograma de edades
            st.markdown("### üìä Distribuci√≥n de edades")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.histplot(df_clientes["Edad"], bins=20, kde=True, ax=ax, color="skyblue")
            ax.set_title("Distribuci√≥n de edades de los clientes")
            ax.set_xlabel("Edad")
            ax.set_ylabel("Cantidad")
            st.pyplot(fig)

            # Top 10 localidades
            st.markdown("### üèôÔ∏è Top 10 Localidades con m√°s clientes")
            top_localidades = df_clientes["Localidad"].value_counts().head(10)
            fig2, ax2 = plt.subplots()
            top_localidades.plot(kind="barh", ax=ax2, color="teal")
            ax2.invert_yaxis()
            ax2.set_title("Top 10 Localidades")
            ax2.set_xlabel("Cantidad de clientes")
            st.pyplot(fig2)

            # Mapa geogr√°fico de clientes (si hay coordenadas)
            if "X" in df_clientes.columns and "Y" in df_clientes.columns:
                st.markdown("### üåç Mapa de distribuci√≥n geogr√°fica")
                mapa = folium.Map(location=[df_clientes["Y"].mean(), df_clientes["X"].mean()], zoom_start=5)
                for _, row in df_clientes.iterrows():
                    folium.CircleMarker(
                        location=[row["Y"], row["X"]],
                        radius=2,
                        color='blue',
                        fill=True,
                        fill_opacity=0.6
                    ).add_to(mapa)
                st_folium(mapa, width=700, height=400)

            # Heatmap de correlaciones
            st.markdown("### üî• Correlaci√≥n entre variables num√©ricas")
            corr = df_clientes.select_dtypes(include=['float64', 'int64']).corr()
            fig3, ax3 = plt.subplots()
            sns.heatmap(corr, annot=True, cmap="coolwarm", ax=ax3)
            ax3.set_title("Heatmap de correlaciones")
            st.pyplot(fig3)

            # Estad√≠sticas descriptivas
            st.subheader("üìã Estad√≠sticas descriptivas")
            st.dataframe(df_clientes.describe())

        elif dataset_opcion == "Compras":
            st.subheader("üõí Exploraci√≥n de Compras")
            st.markdown("‚úÖ Conclusiones preliminares del an√°lisis de Compras: - El volumen principal de compras se concentra en productos de bajo a mediano precio (menos de $1200).\n-Se compran en promedio 9 unidades por operaci√≥n, con pocas compras mayores a 25 unidades..\n- Proveedor 8, seguido de 12 y 7, domina en volumen de compras..\n- No hay relaci√≥n directa entre Precio y Cantidad, lo que sugiere que el tipo de producto define el patr√≥n m√°s que el monto.\n- Existen outliers en precios que podr√≠an representar productos premium, errores de carga o compras especiales.")
          
            df_compras = pd.read_csv("Compra_transformada.csv")

            # Histograma de cantidad de compras
            st.markdown("### üì¶ Distribuci√≥n de cantidad por compra")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.histplot(df_compras["Cantidad"], bins=30, kde=True, ax=ax, color="orange")
            ax.set_title("Distribuci√≥n de cantidades por compra")
            ax.set_xlabel("Cantidad")
            ax.set_ylabel("Frecuencia")
            st.pyplot(fig)

            # Top 10 productos m√°s comprados
            st.markdown("### ü•á Top 10 productos m√°s comprados")
            top_productos = df_compras["IdProducto"].value_counts().head(10)
            fig2, ax2 = plt.subplots()
            top_productos.plot(kind="bar", ax=ax2, color="green")
            ax2.set_title("Top 10 productos por frecuencia de compra")
            ax2.set_xlabel("IdProducto")
            ax2.set_ylabel("N√∫mero de compras")
            st.pyplot(fig2)

            # Heatmap de correlaciones
            st.markdown("### üî• Correlaci√≥n entre variables num√©ricas")
            corr_compras = df_compras.select_dtypes(include=['float64', 'int64']).corr()
            fig4, ax4 = plt.subplots()
            sns.heatmap(corr_compras, annot=True, cmap="coolwarm", ax=ax4)
            ax4.set_title("Heatmap de correlaciones - Compras")
            st.pyplot(fig4)

            # Visualizaci√≥n bivariada: IdProducto vs Cantidad
            st.markdown("### üìä Relaci√≥n entre Producto y Cantidad Comprada")
            fig3, ax3 = plt.subplots(figsize=(10, 4))
            top_ids = df_compras['IdProducto'].value_counts().head(10).index
            sns.boxplot(data=df_compras[df_compras['IdProducto'].isin(top_ids)],
                        x="IdProducto", y="Cantidad", ax=ax3, palette="pastel")
            ax3.set_title("Distribuci√≥n de cantidades por producto (Top 10)")
            st.pyplot(fig3)

            # Estad√≠sticas descriptivas
            st.subheader("üìã Estad√≠sticas descriptivas")
            st.dataframe(df_compras.describe())


        elif dataset_opcion == "Empleados":
            st.subheader("üëî Exploraci√≥n de Empleados")
            st.markdown("‚úÖ Conclusiones preliminares del dataset Empleados:\n- El salario m√°s frecuente es $32.000, y la mayor√≠a de empleados cobra entre $15.000 y $36.000.\n- El rol de vendedor domina la estructura laboral (m√°s del 60% del total).\n- El sector m√°s numeroso es ventas, seguido de administraci√≥n y log√≠stica.\n- Los salarios m√°s altos se encuentran en administraci√≥n y sistemas.\n- Las sucursales est√°n bastante equilibradas, con una leve concentraci√≥n en mor√≥n, caseros y cabildo.")
        
            df_empleados = pd.read_csv("Empleados_transformados.csv")
        
            # Histograma de salarios
            st.markdown("### üíµ Distribuci√≥n de Salarios")
            fig, ax = plt.subplots()
            sns.histplot(df_empleados["Salario"], bins=30, kde=True, ax=ax, color="lightgreen")
            ax.set_title("Distribuci√≥n de salarios")
            st.pyplot(fig)
        
            # Empleados por cargo
            st.markdown("### üë∑‚Äç‚ôÇÔ∏è Distribuci√≥n por Cargo")
            fig2, ax2 = plt.subplots()
            df_empleados["Cargo"].value_counts().plot(kind="bar", ax=ax2, color="steelblue")
            ax2.set_title("Cantidad de empleados por cargo")
            ax2.set_ylabel("Cantidad")
            st.pyplot(fig2)
        
            # Boxplot salario por cargo
            st.markdown("### üìä Salario por Cargo")
            fig3, ax3 = plt.subplots(figsize=(10, 5))
            sns.boxplot(data=df_empleados, x="Cargo", y="Salario", ax=ax3, palette="pastel")
            ax3.set_title("Distribuci√≥n de salario por cargo")
            ax3.tick_params(axis='x', rotation=45)
            st.pyplot(fig3)

            # Gr√°fico de conteo por Sucursal
            st.markdown("### üè¢ Empleados por Sucursal")
            fig1, ax1 = plt.subplots()
            df_empleados['Sucursal'].value_counts().plot(kind='bar', ax=ax1, color='lightblue')
            ax1.set_title("Cantidad de empleados por sucursal")
            st.pyplot(fig1)

            # Gr√°fico de conteo por Sector
            st.markdown("### üóÇÔ∏è Empleados por Sector")
            fig2, ax2 = plt.subplots()
            df_empleados['Sector'].value_counts().plot(kind='bar', ax=ax2, color='lightgreen')
            ax2.set_title("Cantidad de empleados por sector")
            st.pyplot(fig2)

            # Gr√°fico de conteo por Cargo
            st.markdown("### üë∑‚Äç‚ôÇÔ∏è Empleados por Cargo")
            fig3, ax3 = plt.subplots()
            df_empleados['Cargo'].value_counts().plot(kind='bar', ax=ax3, color='salmon')
            ax3.set_title("Cantidad de empleados por cargo")
            st.pyplot(fig3)
           
            # Estad√≠sticas descriptivas
            st.subheader("üìã Estad√≠sticas descriptivas")
            st.dataframe(df_empleados.describe())


        elif dataset_opcion == "Gastos":
            st.subheader("üí∏ Exploraci√≥n de Gastos")
            st.markdown("‚úÖ Conclusiones preliminares del dataset Gasto:\n- El monto promedio por gasto es de $660, con un m√°ximo de casi $1.200.\n- El gasto diario es estable, con picos regulares, lo que sugiere planificaci√≥n.\n- Las sucursales 18, 1 y 2 son las de mayor gasto.\n- Los tipos de gasto 1 y 4 concentran la mayor parte del presupuesto.\n- No se observan outliers ni anomal√≠as significativas.")
        
            df_gastos = pd.read_csv("Gasto_transformado.csv")
        
            # Histograma de montos
            st.markdown("### üí∞ Distribuci√≥n de Montos de Gasto")
            fig1, ax1 = plt.subplots()
            sns.histplot(df_gastos["Monto"], bins=30, kde=True, color="coral", ax=ax1)
            ax1.set_title("Distribuci√≥n de montos de gasto")
            st.pyplot(fig1)
        
            # Gasto por tipo
            st.markdown("### üßæ Gasto por Tipo")
            fig2, ax2 = plt.subplots()
            df_gastos["IdTipoGasto"].value_counts().plot(kind="bar", ax=ax2, color="orchid")
            ax2.set_title("Cantidad de registros por tipo de gasto")
            st.pyplot(fig2)
        
            # Gasto por sucursal
            st.markdown("### üè¢ Gasto total por Sucursal")
            gasto_sucursal = df_gastos.groupby("IdSucursal")["Monto"].sum().sort_values(ascending=False)
            fig3, ax3 = plt.subplots()
            gasto_sucursal.plot(kind="bar", ax=ax3, color="skyblue")
            ax3.set_title("Gasto total por sucursal")
            st.pyplot(fig3)
        
            # Serie temporal de gastos
            st.markdown("### üìÖ Evoluci√≥n temporal de los gastos")
            df_gastos["Fecha"] = pd.to_datetime(df_gastos["Fecha"])
            serie = df_gastos.groupby("Fecha")["Monto"].sum()
            fig4, ax4 = plt.subplots()
            serie.plot(ax=ax4, color="green")
            ax4.set_title("Gastos diarios totales")
            st.pyplot(fig4)
            
            # Heatmap de correlaci√≥n
            st.markdown("### üî• Correlaci√≥n entre variables num√©ricas")
            fig5, ax5 = plt.subplots()
            sns.heatmap(df_gastos.select_dtypes(include="number").corr(), annot=True, cmap="coolwarm", ax=ax5)
            ax5.set_title("Matriz de correlaciones - Gastos")
            st.pyplot(fig5)
            
            # Estad√≠sticas
            st.subheader("üìã Estad√≠sticas descriptivas")
            st.dataframe(df_gastos.describe())
        

        elif dataset_opcion == "Productos":
            st.subheader("üì¶ Exploraci√≥n de Productos")
            st.markdown("‚úÖ Conclusiones del an√°lisis del dataset PRODUCTOS_transformado.csv + Compras:\n- Cat√°logo con 291 productos √∫nicos; destacan impresi√≥n e inform√°tica.\n- 10 tipos de producto; revisar duplicados por concepto.\n- Precios entre $400 y $2000; algunos outliers elevan el promedio.\n- Producto m√°s caro real: NAS QNAP ($9555). M√°s barato: funda para tablet ($3).\n- Top comprados: valijas, cartuchos, mouse pad, etc.\n- Alta rotaci√≥n de insumos sugiere operaci√≥n comercial o institucional.\n- Posible an√°lisis futuro de rentabilidad y rotaci√≥n con datos de ventas.")
        
            df_productos = pd.read_csv("PRODUCTOS_transformado.csv")
            df_compras = pd.read_csv("Compra_transformada.csv")
        
            # Histograma de precios
            st.markdown("### üí∞ Distribuci√≥n de precios (con outliers)")
            fig1, ax1 = plt.subplots()
            sns.histplot(df_productos["Precio"], bins=50, ax=ax1, color="skyblue")
            ax1.set_title("Distribuci√≥n de precios de productos")
            st.pyplot(fig1)
        
            # Productos m√°s comprados con nombres
            st.markdown("### üèÜ Top 10 productos m√°s comprados (con nombre)")
            top_ids = df_compras["IdProducto"].value_counts().head(10).reset_index()
            top_ids.columns = ["IdProducto", "Total"]
            
            # Merge con productos para obtener nombres
            top_nombres = top_ids.merge(df_productos[["ID_PRODUCTO", "Concepto"]], left_on="IdProducto", right_on="ID_PRODUCTO")
            
            fig, ax = plt.subplots()
            sns.barplot(data=top_nombres, x="Total", y="Concepto", ax=ax, palette="Blues_d")
            ax.set_title("Productos m√°s comprados (por nombre)")
            ax.set_xlabel("Cantidad comprada")
            ax.set_ylabel("Producto")
            st.pyplot(fig)

        
            # Top productos m√°s comprados
            st.markdown("### ü•á Productos m√°s comprados (Top 10)")
            top_ids = df_compras["IdProducto"].value_counts().head(10)
            fig3, ax3 = plt.subplots()
            top_ids.plot(kind="bar", ax=ax3, color="lightgreen")
            ax3.set_title("Top productos m√°s comprados")
            ax3.set_xlabel("IdProducto")
            st.pyplot(fig3)
        
            # Estad√≠sticas descriptivas
            st.subheader("üìã Estad√≠sticas descriptivas de precios")
            st.dataframe(df_productos.describe())


        elif dataset_opcion == "Proveedores":
            st.subheader("üè≠ Exploraci√≥n de Proveedores")
            st.markdown("‚úÖ Conclusiones del an√°lisis del dataset Proveedores:\n- Hay un total de 14 proveedores registrados, todos en Argentina.\n- La mayor√≠a se encuentran en la provincia de Buenos Aires, especialmente en el departamento capital.\n- Hay 3 proveedores repetidos por nombre, lo que sugiere sucursales o registros duplicados.\n- El dataset parece limpio, sin valores nulos, aunque podr√≠a mejorarse agregando CUIT, rubros, emails o tel√©fonos.")
        
            df_proveedores = pd.read_csv("Proveedores_transformado.csv")
        
            # Proveedores por provincia
            st.markdown("### üó∫Ô∏è Proveedores por Provincia")
            fig1, ax1 = plt.subplots()
            df_proveedores['State'].value_counts().plot(kind='bar', ax=ax1, color='skyblue')
            ax1.set_title("Cantidad de proveedores por provincia")
            st.pyplot(fig1)
        
            # Proveedores por ciudad
            st.markdown("### üèôÔ∏è Proveedores por Ciudad")
            fig2, ax2 = plt.subplots()
            df_proveedores['City'].value_counts().head(10).plot(kind='bar', ax=ax2, color='coral')
            ax2.set_title("Top 10 ciudades con m√°s proveedores")
            st.pyplot(fig2)
        
            # Duplicados por nombre
            st.markdown("### üîç Posibles Duplicados por Nombre")
            duplicados = df_proveedores['Nombre'].value_counts()
            duplicados = duplicados[duplicados > 1]
            st.dataframe(duplicados)


        elif dataset_opcion == "Sucursales":
            st.subheader("üè¢ Exploraci√≥n de Sucursales")
            st.markdown("‚úÖ Conclusiones del an√°lisis del dataset Sucursales:\n- La empresa tiene 31 sucursales distribuidas en 17 provincias argentinas.\n- La mayor presencia est√° en Buenos Aires (9 sucursales).\n- Varias localidades clave tienen m√°s de una sucursal: CABA, Rosario, Mendoza, etc.\n- Las coordenadas permiten an√°lisis espaciales y mapas.\n- Hay posibles redundancias en nombres de localidades (\"CABA\" y \"Ciudad de Buenos Aires\").")
        
            df_sucursales = pd.read_csv("Sucursales_transformado.csv")
        
            # Conteo por provincia
            st.markdown("### üó∫Ô∏è Cantidad de sucursales por provincia")
            fig1, ax1 = plt.subplots()
            df_sucursales["Provincia"].value_counts().plot(kind="bar", ax=ax1, color="lightblue")
            ax1.set_title("Sucursales por provincia")
            st.pyplot(fig1)
        
            # Conteo por localidad
            st.markdown("### üèôÔ∏è Top localidades con m√°s sucursales")
            fig2, ax2 = plt.subplots()
            df_sucursales["Localidad"].value_counts().head(10).plot(kind="bar", ax=ax2, color="lightgreen")
            ax2.set_title("Top localidades")
            st.pyplot(fig2)
        
            # Mapa de sucursales
            st.markdown("### üåç Mapa geogr√°fico de sucursales")
            mapa = folium.Map(location=[df_sucursales["Latitud"].mean(), df_sucursales["Longitud"].mean()], zoom_start=5)
            for _, row in df_sucursales.iterrows():
                folium.Marker(location=[row["Latitud"], row["Longitud"]], popup=row["Sucursal"]).add_to(mapa)
            st_folium(mapa, width=700, height=400)

        elif dataset_opcion == "Ventas":
            st.subheader("üí∞ Exploraci√≥n de Ventas")
            st.markdown("‚úÖ Conclusiones del an√°lisis del dataset Ventas:\n- El volumen de ventas es muy alto (m√°s de 46.000 registros).\n- La mayor√≠a de las ventas son de 1 a 3 unidades, con pocos casos mayores a 10.\n- Las ventas diarias son constantes, con picos estacionales.\n- Los productos m√°s vendidos incluyen:\n    - Perif√©ricos (mouse pads)\n    - Estucher√≠a (mochilas y fundas)\n    - Insumos (cartuchos, limpiadores)\n- Hay una coherencia importante con los productos m√°s comprados, lo que sugiere buena planificaci√≥n de stock.")
        
            df_ventas = pd.read_csv("Venta_transformado.csv")
            df_ventas["Fecha"] = pd.to_datetime(df_ventas["Fecha"])
        
            # Ventas mensuales
            st.markdown("### üìÖ Ventas mensuales")
            ventas_mensuales = df_ventas.groupby(df_ventas["Fecha"].dt.to_period("M")).size()
            ventas_mensuales.index = ventas_mensuales.index.to_timestamp()
            fig1, ax1 = plt.subplots()
            ventas_mensuales.plot(ax=ax1, color="green")
            ax1.set_title("Ventas mensuales")
            st.pyplot(fig1)
        
          # Ventas por canal
            st.markdown("### üõçÔ∏è Ventas por canal")
            fig2, ax2 = plt.subplots()
            canales = {1: "Tienda F√≠sica", 2: "Online", 3: "Mayorista", 4: "Otros"}
            df_ventas["Canal"] = df_ventas["IdCanal"].map(canales)
            df_ventas["Canal"].value_counts().plot(kind="bar", ax=ax2, color="skyblue")
            ax2.set_title("Cantidad de ventas por canal (con nombres)")
            st.pyplot(fig2)

            # Ventas por sucursal
            st.markdown("### üè¢ Ventas por sucursal")
            fig3, ax3 = plt.subplots()
            df_sucursales = pd.read_csv("Sucursales_transformado.csv")
            sucursal_map = df_sucursales.set_index("ID")["Sucursal"].to_dict()
            df_ventas["Sucursal"] = df_ventas["IdSucursal"].map(sucursal_map)
            df_ventas["Sucursal"].value_counts().plot(kind="bar", ax=ax3, color="orange")
            ax3.set_title("Ventas por sucursal (con nombre)")
            st.pyplot(fig3)
            
            # Top productos m√°s vendidos (con nombre)
            st.markdown("### üèÜ Top 10 productos m√°s vendidos (por nombre)")
            df_productos = pd.read_csv("PRODUCTOS_transformado.csv")
            top_ventas = df_ventas["IdProducto"].value_counts().head(10).reset_index()
            top_ventas.columns = ["IdProducto", "Total"]
            top_ventas = top_ventas.merge(df_productos[["ID_PRODUCTO", "Concepto"]], left_on="IdProducto", right_on="ID_PRODUCTO")
            
            fig, ax = plt.subplots()
            sns.barplot(data=top_ventas, x="Total", y="Concepto", ax=ax, palette="Blues_d")
            ax.set_title("Productos m√°s vendidos (por nombre)")
            ax.set_xlabel("Cantidad vendida")
            ax.set_ylabel("Producto")
            st.pyplot(fig)

            # Estad√≠sticas descriptivas
            st.subheader("üìã Estad√≠sticas descriptivas")
            st.dataframe(df_ventas.describe())


    elif menu == "An√°lisis cruzado":
        st.header("üîÄ An√°lisis cruzado entre √°reas")

        analisis_opcion = st.selectbox("Seleccion√° el an√°lisis cruzado a visualizar:", [
            "üõçÔ∏è Productos m√°s vendidos vs. m√°s comprados",
            "üìç Sucursales con m√°s ventas vs. m√°s gastos",
            "üí∏ Relaci√≥n entre salario de empleados y volumen de ventas",
            "üë• Perfil de cliente vs. tipo de producto vendido",
            "üõí Canal de venta vs. volumen/monto de ventas",
            "üìà Evoluci√≥n hist√≥rica de ventas por canal",
            "üìä Proveedor con mayor volumen de compra",
            "üí° Comparar precios de compra vs. venta por producto (margen)"
        ])

        if analisis_opcion == "üõçÔ∏è Productos m√°s vendidos vs. m√°s comprados":
            st.markdown("### üõçÔ∏è Productos m√°s vendidos vs. m√°s comprados")
            st.markdown("üîé ¬øQu√© muestra el gr√°fico?\n- Comparaci√≥n directa de la cantidad vendida vs. la cantidad comprada por producto.\n- Pod√©s ver claramente si hay productos:\n    - Con m√°s ventas que compras ‚Üí posible falta de stock o desabastecimiento.\n    - Con m√°s compras que ventas ‚Üí posible exceso de stock o baja rotaci√≥n.")

            df_ventas = pd.read_csv("Venta_transformado.csv")
            df_compras = pd.read_csv("Compra_transformada.csv")
            df_productos = pd.read_csv("PRODUCTOS_transformado.csv")

            # Agrupamos ventas y compras por producto
            ventas = df_ventas["IdProducto"].value_counts().reset_index()
            ventas.columns = ["IdProducto", "Cantidad_Vendida"]

            compras = df_compras["IdProducto"].value_counts().reset_index()
            compras.columns = ["IdProducto", "Cantidad_Comprada"]

            # Merge y agregamos nombres
            df_merge = ventas.merge(compras, on="IdProducto", how="outer").fillna(0)
            df_merge = df_merge.merge(df_productos[["ID_PRODUCTO", "Concepto"]], left_on="IdProducto", right_on="ID_PRODUCTO")

            # Top 10 productos por ventas
            top = df_merge.sort_values(by="Cantidad_Vendida", ascending=False).head(10)

            # Gr√°fico comparativo
            st.markdown("### üìä Comparaci√≥n de productos m√°s vendidos y comprados")
            fig, ax = plt.subplots(figsize=(10, 6))
            bar_width = 0.4
            x = range(len(top))

            ax.bar(x, top["Cantidad_Vendida"], width=bar_width, label="Vendidos", color="blue")
            ax.bar([i + bar_width for i in x], top["Cantidad_Comprada"], width=bar_width, label="Comprados", color="orange")
            ax.set_xticks([i + bar_width/2 for i in x])
            ax.set_xticklabels(top["Concepto"], rotation=45, ha="right")
            ax.set_ylabel("Cantidad")
            ax.set_title("Productos m√°s vendidos vs. m√°s comprados")
            ax.legend()
            st.pyplot(fig)

        elif analisis_opcion == "üìç Sucursales con m√°s ventas vs. m√°s gastos":
            st.markdown("### üìç Sucursales con m√°s ventas vs. m√°s gastos")
            st.markdown("üîé ¬øQu√© observamos?\n- Las sucursales con mayor volumen de ventas no siempre son las que m√°s gastan.\n- Algunas sucursales tienen gastos elevados en proporci√≥n a sus ventas, lo que podr√≠a indicar:\n    - Ineficiencia operativa\n    - Costos fijos altos\n    - Gasto en infraestructura/log√≠stica no rentable\n\nüí° Ideal para analizar rentabilidad por punto de venta.")
        
            df_ventas = pd.read_csv("Venta_transformado.csv")
            df_gastos = pd.read_csv("Gasto_transformado.csv")
            df_sucursales = pd.read_csv("Sucursales_transformado.csv")
        
            # Ventas por sucursal
            ventas_sucursal = df_ventas.groupby("IdSucursal").size().reset_index(name="Ventas")
        
            # Gastos por sucursal
            gastos_sucursal = df_gastos.groupby("IdSucursal")["Monto"].sum().reset_index(name="Gastos")
        
            # Merge con nombres de sucursales
            df_merge = ventas_sucursal.merge(gastos_sucursal, on="IdSucursal")
            sucursal_map = df_sucursales.set_index("ID")["Sucursal"].to_dict()
            df_merge["Sucursal"] = df_merge["IdSucursal"].map(sucursal_map)
        
            df_top = df_merge.sort_values(by="Ventas", ascending=False).head(10)
        
            # Gr√°fico comparativo
            fig, ax = plt.subplots(figsize=(10, 6))
            bar_width = 0.4
            x = range(len(df_top))
        
            ax.bar(x, df_top["Ventas"], width=bar_width, label="Ventas", color="blue")
            ax.bar([i + bar_width for i in x], df_top["Gastos"], width=bar_width, label="Gastos", color="orange")
            ax.set_xticks([i + bar_width/2 for i in x])
            ax.set_xticklabels(df_top["Sucursal"], rotation=45, ha="right")
            ax.set_ylabel("Cantidad")
            ax.set_title("Top 10 sucursales con m√°s ventas vs. m√°s gastos")
            ax.legend()
            st.pyplot(fig)

        elif analisis_opcion == "üí∏ Relaci√≥n entre salario de empleados y volumen de ventas":
            st.markdown("### üí∏ Relaci√≥n entre salario de empleados y volumen de ventas")
            st.markdown("üîé ¬øQu√© revela el gr√°fico?.\n- No hay una correlaci√≥n directa fuerte entre salario y ventas generadas.\n- Algunos empleados con salarios medios generan altas ventas, lo cual sugiere alto rendimiento.\n- Tambi√©n hay empleados con salario alto y ventas bajas, lo cual puede indicar o Cargos administrativos o Antig√ºedad o jerarqu√≠a sin tareas comerciales directas.\n- üí° Muy √∫til para evaluar productividad individual y tomar decisiones sobre incentivos o comisiones.")
        
            df_empleados = pd.read_csv("Empleados_transformados.csv")
            df_ventas = pd.read_csv("Venta_transformado.csv")
    
            ventas_empleado = df_ventas.groupby("IdEmpleado").size().reset_index(name="Ventas")
            empleados_merge = df_empleados.merge(ventas_empleado, left_on="ID_empleado", right_on="IdEmpleado", how="left").fillna(0)
            top_20 = empleados_merge.sort_values(by="Ventas", ascending=False).head(20)
    
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.scatterplot(data=top_20, x="Salario", y="Ventas", hue="Nombre", ax=ax)
            ax.set_title("Relaci√≥n entre salario y volumen de ventas (Top 20 empleados)")
            st.pyplot(fig)
    
            # Comparador entre dos empleados
            st.markdown("### ü§ù Comparador entre empleados")
            opciones = top_20["Nombre"].tolist()
            col1, col2 = st.columns(2)
            with col1:
                emp1 = st.selectbox("Empleado 1", opciones, key="emp1")
            with col2:
                emp2 = st.selectbox("Empleado 2", opciones, key="emp2")
    
            emp_data = top_20[top_20["Nombre"].isin([emp1, emp2])]
            fig2, ax2 = plt.subplots()
            sns.barplot(data=emp_data, x="Nombre", y="Ventas", ax=ax2, palette="viridis")
            ax2.set_title("Comparaci√≥n de volumen de ventas entre empleados")
            st.pyplot(fig2)

        elif analisis_opcion == "üë• Perfil de cliente vs. tipo de producto vendido":
            st.markdown("### üë• Perfil de cliente vs. tipo de producto vendido")
            st.markdown("üîé ¬øQu√© revela el gr√°fico?\n- Analiza qu√© tipo de productos prefieren distintos perfiles de clientes seg√∫n edad.\n- Permite identificar patrones de consumo, segmentaciones de marketing y oportunidades de fidelizaci√≥n.\n\nüí° Ideal para definir campa√±as espec√≠ficas para cada grupo etario.")
        
            df_clientes = pd.read_csv("Clientes_transformados.csv")
            df_ventas = pd.read_csv("Venta_transformado.csv")
            df_productos = pd.read_csv("PRODUCTOS_transformado.csv")
        
            # Merge para cruzar cliente + venta + producto
            df_ventas = df_ventas.merge(df_clientes, left_on="IdCliente", right_on="ID", how="left")
            df_ventas = df_ventas.merge(df_productos[["ID_PRODUCTO", "Tipo"]], left_on="IdProducto", right_on="ID_PRODUCTO", how="left")
        
            # Crear grupos etarios
            df_ventas.dropna(subset=["Edad", "Tipo"], inplace=True)
            df_ventas["Edad_grupo"] = pd.cut(df_ventas["Edad"], bins=[0, 20, 35, 50, 100], labels=["‚â§20", "21-35", "36-50", ">50"])
        
            # Gr√°fico
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.countplot(data=df_ventas, x="Tipo", hue="Edad_grupo", ax=ax)
            ax.set_title("Tipo de producto vendido seg√∫n grupo etario del cliente")
            ax.set_xlabel("Tipo de producto")
            ax.set_ylabel("Cantidad de ventas")
            ax.tick_params(axis='x', rotation=45)
            st.pyplot(fig)
        
        elif analisis_opcion == "üõí Canal de venta vs. volumen/monto de ventas":
            st.markdown("### üõí Canal de venta vs. volumen/monto de ventas")
            st.markdown("üîé ¬øQu√© revela el gr√°fico?\n- Compara el volumen y la distribuci√≥n de ventas por canal.\n- Permite identificar cu√°l canal tiene mayor actividad o ingresos.\n\nüí° √ötil para ajustar estrategias comerciales y reforzar canales m√°s rentables.")
        
            # Carga de datasets
            df_ventas = pd.read_csv("Venta_transformado.csv")
            df_productos = pd.read_csv("PRODUCTOS_transformado.csv")
            df_canal = pd.read_csv("CanalDeVenta_Tranfor.csv")
        
            # Asegurar formatos consistentes
            df_ventas["IdCanal"] = df_ventas["IdCanal"].astype(str).str.strip()
            df_canal["CODIGO"] = df_canal["CODIGO"].astype(str).str.strip()
        
            # Merge para obtener nombre de canal y precio real
            df_ventas = df_ventas.merge(df_canal, left_on="IdCanal", right_on="CODIGO", how="left")
            df_ventas = df_ventas.merge(df_productos[["ID_PRODUCTO", "Precio"]].rename(columns={"Precio": "PrecioUnitario"}), left_on="IdProducto", right_on="ID_PRODUCTO", how="left")
        
            # Agrupamos por canal
            canal_resumen = df_ventas.groupby("DESCRIPCION").agg({
                "IdVenta": "count",
                "PrecioUnitario": "sum"
            }).reset_index().rename(columns={
                "IdVenta": "Total_Vendido",
                "PrecioUnitario": "Monto_Total"
            })
        
            # Visualizaci√≥n combinada
            fig, ax1 = plt.subplots(figsize=(10, 6))
            sns.barplot(data=canal_resumen, x="DESCRIPCION", y="Total_Vendido", ax=ax1, color="skyblue")
            ax1.set_ylabel("Cantidad de ventas", color="skyblue")
            ax1.set_xlabel("Canal de venta")
            ax1.set_title("Volumen y monto de ventas por canal")
            ax1.tick_params(axis='y', labelcolor="skyblue")
            plt.xticks(rotation=30)
        
            # Eje secundario para monto total
            ax2 = ax1.twinx()
            sns.lineplot(data=canal_resumen, x="DESCRIPCION", y="Monto_Total", ax=ax2, color="darkblue", marker="o")
            ax2.set_ylabel("Monto total ($)", color="darkblue")
            ax2.tick_params(axis='y', labelcolor="darkblue")
        
            st.pyplot(fig)
            
        elif analisis_opcion == "üìä Proveedor con mayor volumen de compra":
            st.markdown("### üìä Proveedor con mayor volumen de compra")
            st.markdown("üîé ¬øQu√© muestra el gr√°fico?\n- Permite identificar cu√°les proveedores concentran mayor cantidad de productos adquiridos.\n- Ayuda a tomar decisiones sobre negociaci√≥n, dependencia o diversificaci√≥n de proveedores.\n\nüí° Ideal para compras estrat√©gicas y an√°lisis de riesgo.")
        
            df_compras = pd.read_csv("Compra_transformada.csv")
            df_proveedores = pd.read_csv("Proveedores_transformado.csv")
        
            # Agrupar por proveedor
            proveedor_resumen = df_compras.groupby("IdProveedor")["Cantidad"].sum().reset_index()
            proveedor_resumen = proveedor_resumen.merge(df_proveedores, left_on="IdProveedor", right_on="IDProveedor", how="left")
            proveedor_resumen = proveedor_resumen.sort_values(by="Cantidad", ascending=False).head(10)
        
            # Gr√°fico
            fig, ax = plt.subplots(figsize=(10, 5))
            sns.barplot(data=proveedor_resumen, x="Nombre", y="Cantidad", ax=ax, palette="magma")
            ax.set_title("Top 10 proveedores por volumen de compra")
            ax.set_ylabel("Cantidad total de productos comprados")
            ax.set_xlabel("Proveedor")
            ax.tick_params(axis='x', rotation=45)
            st.pyplot(fig)
            
        elif analisis_opcion == "üìà Evoluci√≥n hist√≥rica de ventas por canal":
            st.markdown("### üìà Evoluci√≥n hist√≥rica de ventas por canal")
            st.markdown("üîé ¬øQu√© revela el gr√°fico?\n- Muestra c√≥mo evolucionaron las ventas en el tiempo seg√∫n el canal de comercializaci√≥n.\n- Ayuda a detectar estacionalidades, tendencias de migraci√≥n entre canales, y evaluar desempe√±o a largo plazo.\n\nüí° Ideal para planificaci√≥n comercial y campa√±as estacionales.")
        
            df_ventas = pd.read_csv("Venta_transformado.csv")
            df_canal = pd.read_csv("CanalDeVenta_Tranfor.csv")
        
            df_ventas["Fecha"] = pd.to_datetime(df_ventas["Fecha"])
            df_ventas["IdCanal"] = df_ventas["IdCanal"].astype(str).str.strip()
            df_canal["CODIGO"] = df_canal["CODIGO"].astype(str).str.strip()
            df_ventas = df_ventas.merge(df_canal, left_on="IdCanal", right_on="CODIGO", how="left")
        
            df_ventas["Mes"] = df_ventas["Fecha"].dt.to_period("M").dt.to_timestamp()
            resumen = df_ventas.groupby(["Mes", "DESCRIPCION"]).size().reset_index(name="Cantidad")
        
            fig = px.line(
                resumen,
                x="Mes",
                y="Cantidad",
                color="DESCRIPCION",
                markers=True,
                title="Evoluci√≥n mensual de ventas por canal",
                labels={"DESCRIPCION": "Canal de Venta", "Mes": "Fecha", "Cantidad": "Cantidad de Ventas"},
            )
            st.plotly_chart(fig, use_container_width=True)

        elif analisis_opcion == "üí° Comparar precios de compra vs. venta por producto (margen)":
            st.markdown("### üí° Comparar precios de compra vs. venta por producto (margen)")
            st.markdown("üîé ¬øQu√© muestra el gr√°fico?\n- Compara el precio promedio de compra y venta de cada producto.\n- Muestra el margen estimado por unidad.\n\nüí° Muy √∫til para an√°lisis de rentabilidad por producto y toma de decisiones comerciales.")
        
            df_ventas = pd.read_csv("Venta_transformado.csv")
            df_compras = pd.read_csv("Compra_transformada.csv")
            df_productos = pd.read_csv("PRODUCTOS_transformado.csv")
        
            # Precio promedio de compra por producto
            compra_por_prod = df_compras.groupby("IdProducto")["Precio"].mean().reset_index(name="Precio_Compra")
        
            # Precio promedio de venta por producto
            venta_por_prod = df_ventas.groupby("IdProducto")["Precio"].mean().reset_index(name="Precio_Venta")
        
            # Merge de ambos
            comparacion = compra_por_prod.merge(venta_por_prod, on="IdProducto")
            comparacion = comparacion.merge(df_productos[["ID_PRODUCTO", "Concepto"]], left_on="IdProducto", right_on="ID_PRODUCTO")
            comparacion["Margen"] = comparacion["Precio_Venta"] - comparacion["Precio_Compra"]
            comparacion = comparacion.sort_values(by="Margen", ascending=False).head(10)
        
            # Gr√°fico
            fig, ax = plt.subplots(figsize=(10, 6))
            comparacion.set_index("Concepto")[["Precio_Compra", "Precio_Venta"]].plot(kind="bar", ax=ax)
            ax.set_title("Comparaci√≥n de precios de compra vs. venta (Top 10 por margen)")
            ax.set_ylabel("Precio promedio por unidad")
            ax.set_xlabel("Producto")
            plt.xticks(rotation=45, ha="right")
            st.pyplot(fig)

##############                       
####  ML  ####
##############
    elif menu == "Modelos de ML":
        st.header("ü§ñ Modelos de Machine Learning")
    
        categoria = st.selectbox("üìä Eleg√≠ una categor√≠a de datos:", [
            "üõçÔ∏è Compras",
            "üßæ Ventas",
            "üë• Empleados",
            "üß© Sucursales",
            "üí∏ Gastos",
            "üì¶ Productos",
            "üöö Proveedores",
            "üåê Canal de ventas"
        ])
        # -----------------------------
        # COMPRAS
        # -----------------------------
        if categoria == "üõçÔ∏è Compras":
            st.subheader("üõçÔ∏è Predicci√≥n de demanda de productos")
            modelo = st.selectbox("Eleg√≠ un modelo de ML:", [
                "Regresi√≥n Lineal", "Random Forest", "ARIMA (Series Temporales)"
            ])
    
            @st.cache_data
            def load_compras():
                return pd.read_csv("Compra_transformada.csv", parse_dates=["Fecha"])
            
            df = load_compras()
    
            if modelo in ["Regresi√≥n Lineal", "Random Forest"]:
                df["mes"] = df["Fecha"].dt.month
                df["a√±o"] = df["Fecha"].dt.year
    
                features = ["mes", "a√±o"]
                if "IdProducto" in df.columns:
                    features.append("IdProducto")
                if "IdProveedor" in df.columns:
                    features.append("IdProveedor")
    
                X = df[features]
                y = df["Cantidad"]
    
                X = pd.get_dummies(X, columns=["IdProducto", "IdProveedor"], drop_first=True)
    
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42)
    
                if modelo == "Regresi√≥n Lineal":
                    model = LinearRegression()
                    st.markdown("#### üß† Sobre el modelo: Regresi√≥n Lineal")
                    st.markdown("""
                    Modelo simple que busca predecir la cantidad comprada a partir de variables como mes, a√±o, producto y proveedor.  
                    Es √∫til para observar tendencias generales.
                    """)
                else:
                    model = RandomForestRegressor(n_estimators=100, random_state=42)
                    st.markdown("#### üå≤ Sobre el modelo: Random Forest")
                    st.markdown("""
                    Modelo basado en √°rboles de decisi√≥n, m√°s robusto ante relaciones no lineales.  
                    Mejora la precisi√≥n en escenarios m√°s complejos como compras por proveedor y producto.
                    """)
    
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
    
                try:
                    rmse = np.sqrt(mean_squared_error(y_test, np.ravel(y_pred)))
                    st.write(f"üîç Error cuadr√°tico medio (RMSE): {rmse:.2f}")
                except Exception as e:
                    st.error(f"‚ùå Error en c√°lculo de RMSE: {e}")
    
                try:
                    st.markdown("#### üìä Comparaci√≥n entre valores reales y predichos")
                    chart_df = pd.DataFrame({
                        "Real": y_test.values[:50],
                        "Predicho": np.ravel(y_pred)[:50]
                    })
                    st.line_chart(chart_df)
                except Exception as e:
                    st.error(f"‚ùå Error en gr√°fico: {e}")
    
            elif modelo == "ARIMA (Series Temporales)":
                st.info("Usando solo la serie temporal agregada total por mes.")
                st.markdown("#### ‚è≥ Sobre el modelo: ARIMA")
                st.markdown("""
                ARIMA es un modelo estad√≠stico para series temporales que predice la cantidad total de productos comprados mes a mes, 
                a partir del comportamiento hist√≥rico de la demanda.
                """)
    
                df_ts = df.copy()
                df_ts = df_ts.set_index("Fecha").resample("M").sum(numeric_only=True)["Cantidad"]
    
                st.line_chart(df_ts)
    
                try:
                    model = sm.tsa.ARIMA(df_ts, order=(1, 1, 1))
                    results = model.fit()
                    forecast = results.forecast(steps=6)
    
                    st.write("üìà Predicci√≥n para los pr√≥ximos 6 meses:")
                    st.line_chart(forecast)
                except Exception as e:
                    st.error(f"‚ùå Error en modelo ARIMA: {e}")
    
        # -----------------------------
        # VENTAS
        # -----------------------------
        elif categoria == "üßæ Ventas":
            st.subheader("üßæ An√°lisis de ventas: predicci√≥n y detecci√≥n de outliers")
    
            tarea = st.radio("¬øQu√© quer√©s hacer?", [
                "üîÆ Predicci√≥n de ventas futuras",
                "üö® Detecci√≥n de outliers o fraudes"
            ])
    
            @st.cache_data
            def load_ventas():
                return pd.read_csv("Venta_transformado.csv", parse_dates=["Fecha"])
            
            df = load_ventas()
    
            df["mes"] = df["Fecha"].dt.month
            df["a√±o"] = df["Fecha"].dt.year
    
            if tarea == "üîÆ Predicci√≥n de ventas futuras":
                st.markdown("#### üîÆ Predicci√≥n de ventas con Regresi√≥n Ridge")
                st.markdown("""
                Se busca predecir la cantidad vendida usando Regresi√≥n Ridge, una t√©cnica √∫til cuando hay muchas variables 
                correlacionadas (producto, canal, mes, a√±o).
                """)
    
                features = ["mes", "a√±o", "IdProducto", "IdCanal"]
                X = df[features]
                y = df["Cantidad"]
    
                X = pd.get_dummies(X, columns=["IdProducto", "IdCanal"], drop_first=True)
    
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42)
    
                model = Ridge(alpha=1.0)
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
    
                try:
                    rmse = np.sqrt(mean_squared_error(y_test, np.ravel(y_pred)))
                    st.write(f"üîç Error cuadr√°tico medio (RMSE): {rmse:.2f}")
                except Exception as e:
                    st.error(f"‚ùå Error en c√°lculo de RMSE: {e}")
    
                try:
                    st.markdown("#### üìä Comparaci√≥n entre valores reales y predichos")
                    chart_df = pd.DataFrame({
                        "Real": y_test.values[:50],
                        "Predicho": np.ravel(y_pred)[:50]
                    })
                    st.line_chart(chart_df)
                except Exception as e:
                    st.error(f"‚ùå Error en gr√°fico: {e}")
    
            elif tarea == "üö® Detecci√≥n de outliers o fraudes":
                st.markdown("#### üö® Detecci√≥n de outliers con Isolation Forest")
                st.markdown("""
                Isolation Forest detecta ventas inusuales en funci√≥n de precio y cantidad.  
                Los puntos an√≥malos podr√≠an ser errores de carga, promociones extremas o fraudes.
                """)
    
                df_filtrado = df[["Cantidad", "Precio"]].dropna()
                modelo_iso = IsolationForest(contamination=0.02, random_state=42)
                df_filtrado["anomaly"] = modelo_iso.fit_predict(df_filtrado)
                df_filtrado["color"] = df_filtrado["anomaly"].map({1: "Normal", -1: "Outlier"})
    
                st.markdown("#### üìå Resultados de detecci√≥n")
                st.write(df_filtrado["color"].value_counts())
    
                try:
                    fig = px.scatter(df_filtrado, x="Precio", y="Cantidad", color="color",
                                     title="Detecci√≥n de outliers en ventas")
                    st.plotly_chart(fig)
                except Exception as e:
                    st.error(f"‚ùå Error en visualizaci√≥n: {e}")

        # -----------------------------
        # EMPLEADOS
        # -----------------------------
        elif categoria == "üë• Empleados":
            st.subheader("üë• An√°lisis de productividad y rendimiento")
        
            analisis = st.radio("Seleccion√° el tipo de an√°lisis:", [
                "üîç Clusterizaci√≥n por rendimiento (K-means)",
                "üß† Clasificaci√≥n de alto rendimiento (Regresi√≥n log√≠stica)"
            ])
        
            @st.cache_data
            def load_empleados():
                return pd.read_csv("Empleados_transformados.csv")
        
            df = load_empleados()
        
            if analisis == "üîç Clusterizaci√≥n por rendimiento (K-means)":
                st.markdown("#### üîç Agrupamiento de empleados seg√∫n patrones comunes")
                st.markdown("""
                Usamos **K-means**, un algoritmo de clustering no supervisado, para identificar grupos de empleados con patrones similares
                seg√∫n variables como **salario**, **sector**, **cargo** y **sucursal**. Esto permite detectar posibles desequilibrios,
                como empleados con sueldos altos en sectores menos productivos.
                """)
        
                from sklearn.preprocessing import StandardScaler
                from sklearn.cluster import KMeans
        
                # Codificar variables categ√≥ricas
                df_encoded = pd.get_dummies(df[["Salario", "Sucursal", "Sector", "Cargo"]], drop_first=True)
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(df_encoded)
        
                k = st.slider("Eleg√≠ el n√∫mero de clusters", 2, 6, 3)
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                clusters = kmeans.fit_predict(X_scaled)
                df["Cluster"] = clusters
        
                st.write("### Distribuci√≥n de empleados por cluster")
                st.write(df["Cluster"].value_counts().sort_index())
        
                try:
                    fig = px.scatter(df, x="Salario", y="Cluster", color="Sector", hover_data=["Cargo", "Sucursal"],
                                     title="Empleados agrupados por rendimiento relativo")
                    st.plotly_chart(fig)
                except Exception as e:
                    st.error(f"\u274c Error en visualizaci√≥n: {e}")
        
            elif analisis == "üß† Clasificaci√≥n de alto rendimiento (Regresi√≥n log√≠stica)":
                st.markdown("#### üß† Clasificaci√≥n de empleados con alto rendimiento")
                st.markdown("""
                En este modelo simulamos una clasificaci√≥n de empleados como **alto rendimiento** si est√°n en el percentil superior
                de salario. Se entrena una **Regresi√≥n Log√≠stica** para predecir esta condici√≥n a partir de sector, sucursal y cargo.
                """)
        
                from sklearn.linear_model import LogisticRegression
                from sklearn.metrics import classification_report, confusion_matrix
        
                # Crear variable binaria de alto rendimiento
                salario_limite = df["Salario"].quantile(0.75)
                df["alto_rendimiento"] = (df["Salario"] > salario_limite).astype(int)
        
                X = pd.get_dummies(df[["Sucursal", "Sector", "Cargo"]], drop_first=True)
                y = df["alto_rendimiento"]
        
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
                model = LogisticRegression(max_iter=500)
                model.fit(X_train, y_train)
        
                y_pred = model.predict(X_test)
                report = classification_report(y_test, y_pred, output_dict=True)
                cm = confusion_matrix(y_test, y_pred)
        
                st.write("### Matriz de confusi√≥n")
                st.write(pd.DataFrame(cm, index=["No Alto", "Alto"], columns=["Predicho No", "Predicho Alto"]))
        
                st.write("### M√©tricas de clasificaci√≥n")
                st.json({
                    "Precisi√≥n (Clase Alta)": f"{report['1']['precision']:.2f}",
                    "Recall (Clase Alta)": f"{report['1']['recall']:.2f}",
                    "F1-score (Clase Alta)": f"{report['1']['f1-score']:.2f}"
                })


# -----------------------------
# SUCURSALES
# -----------------------------
        elif categoria == "üß© Sucursales":
            st.subheader("üß© Sucursales")
        
            submenu = st.radio("Seleccion√° el tipo de an√°lisis:", [
                "üßπ Cluster geogr√°fico de sucursales",
                "üìä Clasificaci√≥n por volumen de ventas"
            ])
        
            @st.cache_data
            def load_sucursales():
                return pd.read_csv("Sucursales_transformado.csv")
        
            @st.cache_data
            def load_ventas():
                return pd.read_csv("Venta_transformado.csv", parse_dates=["Fecha"])
        
            if submenu == "üßπ Cluster geogr√°fico de sucursales":
                algoritmo = st.selectbox("Eleg√≠ el algoritmo de clusterizaci√≥n:", ["KMeans", "DBSCAN"])
                df = load_sucursales()
                coords = df[["Latitud", "Longitud"]].dropna()
        
                st.markdown("#### üìÖ Objetivo del an√°lisis")
                st.markdown("""
                Este an√°lisis agrupa sucursales seg√∫n su ubicaci√≥n geogr√°fica. 
                Se busca identificar √°reas de concentraci√≥n o zonas con comportamiento similar, 
                lo cual puede ser √∫til para tomar decisiones log√≠sticas, comerciales o de expansi√≥n.
                """)
        
                if algoritmo == "KMeans":
        
                    st.markdown("#### üîç Clustering con KMeans")
                    st.markdown("""
                    KMeans divide las sucursales en un n√∫mero fijo de grupos, buscando minimizar la distancia dentro de cada cluster. 
                    Es √∫til para ver agrupamientos espec√≠ficos seg√∫n cercan√≠a.
                    """)
        
                    k = st.slider("Seleccion√° la cantidad de clusters", 2, 6, 3)
                    scaler = StandardScaler()
                    coords_scaled = scaler.fit_transform(coords)
                    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                    df["Cluster"] = kmeans.fit_predict(coords_scaled)
        
                elif algoritmo == "DBSCAN":
                    from sklearn.cluster import DBSCAN
                    from sklearn.preprocessing import StandardScaler
        
                    st.markdown("#### üîé Clustering con DBSCAN")
                    st.markdown("""
                    DBSCAN encuentra agrupamientos naturales basados en la densidad de puntos, sin necesidad de indicar la cantidad de clusters. 
                    Es √∫til para detectar zonas aisladas o con concentraci√≥n geogr√°fica alta.
                    """)
        
                    eps = st.slider("Seleccion√° el radio de agrupamiento (eps)", 0.01, 1.0, 0.2, step=0.01)
                    min_samples = st.slider("Cantidad m√≠nima de sucursales por grupo", 2, 10, 3)
        
                    scaler = StandardScaler()
                    coords_scaled = scaler.fit_transform(coords)
                    dbscan = DBSCAN(eps=eps, min_samples=min_samples)
                    df["Cluster"] = dbscan.fit_predict(coords_scaled)
        
                st.markdown("#### üåç Mapa de clusters geogr√°ficos")
                try:
                    fig = px.scatter_mapbox(
                        df,
                        lat="Latitud",
                        lon="Longitud",
                        color="Cluster",
                        hover_name="Sucursal",
                        zoom=4,
                        height=600,
                        mapbox_style="open-street-map",
                        title="Distribuci√≥n de sucursales por cluster geogr√°fico"
                    )
                    st.plotly_chart(fig)
                except Exception as e:
                    st.error(f"‚ùå Error al generar el mapa: {e}")
        
                st.markdown("#### üî¢ An√°lisis final")
                st.markdown("""
                El resultado de la clusterizaci√≥n permite observar patrones de agrupamiento espacial entre sucursales.
                - Si las sucursales est√°n bien agrupadas, podr√≠an compartirse log√≠stica, recursos o estrategias regionales.
                - Las sucursales aisladas o con comportamiento at√≠pico podr√≠an requerir un an√°lisis individualizado o mejoras espec√≠ficas.
                - Con DBSCAN, la detecci√≥n de outliers espaciales puede ayudar a identificar sucursales que no pertenecen a ning√∫n cluster estable,
                  lo que podr√≠a indicar una oportunidad de mejora o una estrategia personalizada.
                """)
        
            elif submenu == "üìä Clasificaci√≥n por volumen de ventas":
                st.markdown("#### üìä Agrupamiento de sucursales seg√∫n nivel de ventas")
                st.markdown("""
                En este an√°lisis usamos un modelo de √°rbol de decisi√≥n para predecir qu√© categor√≠a de ventas tiene cada sucursal: 
                **Altas**, **Medias** o **Bajas**, bas√°ndonos en sus registros hist√≥ricos.
                Esto permite entender qu√© variables (como ventas promedio, varianza o cantidad de registros) explican mejor su desempe√±o.
                """)
        
                df_ventas = load_ventas()
                ventas_por_sucursal = df_ventas.groupby("IdSucursal")["Cantidad"].agg([
                    ("TotalVentas", "sum"),
                    ("PromedioVentas", "mean"),
                    ("MaxVentas", "max"),
                    ("MinVentas", "min"),
                    ("Desvio", "std"),
                    ("CantidadRegistros", "count")
                ]).reset_index()
        
                # Crear etiquetas
                q1 = ventas_por_sucursal["TotalVentas"].quantile(0.33)
                q2 = ventas_por_sucursal["TotalVentas"].quantile(0.66)
        
                def clasificar(x):
                    if x < q1:
                        return "Bajas"
                    elif x < q2:
                        return "Medias"
                    else:
                        return "Altas"
        
                ventas_por_sucursal["Categoria"] = ventas_por_sucursal["TotalVentas"].apply(clasificar)
        
                X = ventas_por_sucursal.drop(columns=["Categoria", "IdSucursal"])
                y = ventas_por_sucursal["Categoria"]
        
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
                model = DecisionTreeClassifier(max_depth=3, random_state=42)
                model.fit(X_train, y_train)
        
                y_pred = model.predict(X_test)
        
                st.write("### Matriz de confusi√≥n")
                st.write(pd.DataFrame(confusion_matrix(y_test, y_pred),
                                      index=model.classes_,
                                      columns=["Pred. " + c for c in model.classes_]))
        
                st.write("### M√©tricas de clasificaci√≥n")
                st.text(classification_report(y_test, y_pred))
        
                df = load_sucursales()
                df = df.merge(ventas_por_sucursal[["IdSucursal", "Categoria"]], left_on="ID", right_on="IdSucursal", how="left")
        
                try:
                    st.markdown("#### üåç Mapa de sucursales por categor√≠a de ventas")
                    fig = px.scatter_mapbox(
                        df,
                        lat="Latitud",
                        lon="Longitud",
                        color="Categoria",
                        hover_name="Sucursal",
                        zoom=4,
                        height=600,
                        mapbox_style="open-street-map",
                        title="Sucursal agrupadas por nivel de ventas"
                    )
                    st.plotly_chart(fig)
                except Exception as e:
                    st.error(f"\u274c Error al generar el mapa de ventas: {e}")
        
                st.markdown("#### üî¢ An√°lisis final")
                st.markdown("""
                Gracias al modelo de √°rbol de decisi√≥n pudimos identificar las variables que mejor explican el rendimiento de ventas por sucursal.
                Este an√°lisis no solo agrupa, sino que ayuda a explicar y anticipar comportamientos seg√∫n patrones hist√≥ricos.
                Puede ser de gran valor para tomar decisiones de inversi√≥n o asignaci√≥n de recursos.
                """)
       # -----------------------------
        # GASTOS
        # -----------------------------
        elif categoria == "üí∏ Gastos":
            st.subheader("üí∏ An√°lisis de gastos")
        
            submenu = st.radio("Seleccion√° el tipo de an√°lisis:", [
                "üìä An√°lisis general de gastos",
                "üè¢ An√°lisis por sucursal",
                "üßæ An√°lisis por tipo de gasto"
            ])
        
            @st.cache_data
            def load_gastos():
                return pd.read_csv("Gasto_transformado.csv", parse_dates=["Fecha"])
        
            @st.cache_data
            def load_tipos_gasto():
                return pd.read_csv("TiposDeGasto_T.csv")
        
            @st.cache_data
            def load_sucursales():
                return pd.read_csv("Sucursales_transformado.csv")
        
            df = load_gastos()
            df_tipos = load_tipos_gasto()
            df_suc = load_sucursales()
        
            if submenu == "üìä An√°lisis general de gastos":
                st.markdown("#### üìä Detecci√≥n general de outliers con Isolation Forest")
        
                df = df.merge(df_tipos, left_on="IdTipoGasto", right_on="IdTipoGasto", how="left")
                df = df.merge(df_suc, left_on="IdSucursal", right_on="ID", how="left")
        
                df_filtrado = df[["Monto", "Descripcion", "Sucursal"]].dropna()
                modelo_iso = IsolationForest(contamination=0.05, random_state=42)
                df_filtrado["anomaly"] = modelo_iso.fit_predict(df_filtrado[["Monto"]])
                df_filtrado["color"] = df_filtrado["anomaly"].map({1: "Normal", -1: "At√≠pico"})
        
                st.markdown("#### üìå Resumen de detecciones")
                st.dataframe(df_filtrado[df_filtrado["color"] == "At√≠pico"].sort_values(by="Monto", ascending=False))
        
                try:
                    fig = px.scatter(df_filtrado, x="Descripcion", y="Monto", color="color", 
                                     hover_data=["Sucursal"], title="Gastos detectados como at√≠picos por tipo")
                    st.plotly_chart(fig)
                except Exception as e:
                    st.error(f"‚ùå Error al generar el gr√°fico: {e}")
        
            elif submenu == "üè¢ An√°lisis por sucursal":
                st.markdown("#### üè¢ Historial de gastos por sucursal con media general")
        
                df = df.merge(df_suc, left_on="IdSucursal", right_on="ID", how="left")
                df_grouped = df.groupby(["Fecha", "Sucursal"]).agg({"Monto": "sum"}).reset_index()
        
                sucursales_disp = df_grouped["Sucursal"].dropna().unique().tolist()
                sucursales_seleccionadas = st.multiselect("Seleccion√° una o m√°s sucursales:", sucursales_disp, default=sucursales_disp)
                df_grouped = df_grouped[df_grouped["Sucursal"].isin(sucursales_seleccionadas)]
        
                promedio = df_grouped.groupby("Fecha")["Monto"].mean().reset_index(name="MediaGeneral")
                df_plot = df_grouped.merge(promedio, on="Fecha")
        
                try:
                    fig = px.line(df_plot, x="Fecha", y="Monto", color="Sucursal",
                                  title="Evoluci√≥n de gastos por sucursal", labels={"Monto": "Monto gastado"})
                    fig.add_scatter(x=df_plot["Fecha"], y=df_plot["MediaGeneral"], mode="lines",
                                    name="Media General", line=dict(color="black", dash="dash"))
                    st.plotly_chart(fig)
                except Exception as e:
                    st.error(f"‚ùå Error en gr√°fico hist√≥rico: {e}")
        
            elif submenu == "üßæ An√°lisis por tipo de gasto":
                st.markdown("#### üßæ Outliers dentro de cada tipo de gasto")
        
                df = df.merge(df_tipos, left_on="IdTipoGasto", right_on="IdTipoGasto", how="left")
                df = df.merge(df_suc, left_on="IdSucursal", right_on="ID", how="left")
        
                tipos = df["Descripcion"].dropna().unique()
                tipo_seleccionado = st.selectbox("Seleccion√° un tipo de gasto:", tipos)
        
                df_tipo = df[df["Descripcion"] == tipo_seleccionado]
                df_tipo = df_tipo[["Monto", "Sucursal"]].dropna()

                modelo_tipo = IsolationForest(contamination=0.05, random_state=42)
                df_tipo["anomaly"] = modelo_tipo.fit_predict(df_tipo[["Monto"]])
                df_tipo["color"] = df_tipo["anomaly"].map({1: "Normal", -1: "At√≠pico"})
        
                st.markdown(f"#### üìä Detecci√≥n de outliers en {tipo_seleccionado}")
                st.dataframe(df_tipo[df_tipo["color"] == "At√≠pico"])  # Mostrar detalle con sucursal
        
                try:
                    fig = px.scatter(df_tipo, x="Sucursal", y="Monto", color="color",
                                     title=f"Outliers detectados en {tipo_seleccionado}")
                    st.plotly_chart(fig)
                except Exception as e:
                    st.error(f"‚ùå Error al generar el gr√°fico: {e}")

        # -----------------------------
        # PRODUCTOS
        # -----------------------------
        elif categoria == "üì¶ Productos":
            st.subheader("üì¶ An√°lisis de productos")
        
            submenu = st.radio("Seleccion√° el tipo de an√°lisis:", [
                "ü§ù Recomendaci√≥n de productos",
                "üìà Predicci√≥n temporal de ventas",
                "üîù Top 10 productos por mes"
            ])
        
            @st.cache_data
            def load_ventas():
                return pd.read_csv("Venta_transformado.csv", parse_dates=["Fecha"])
        
            @st.cache_data
            def load_productos():
                return pd.read_csv("PRODUCTOS_transformado.csv")
        
            df_ventas = load_ventas()
            df_productos = load_productos()
        
            if submenu == "ü§ù Recomendaci√≥n de productos":
                st.markdown("#### ü§ù Sistema de recomendaci√≥n basado en volumen de compra")
                st.markdown("""
                Este sistema utiliza KNN (vecinos m√°s cercanos) para encontrar productos relacionados 
                seg√∫n los patrones de compra de los clientes. 
                Recomendamos productos similares al seleccionado, bas√°ndonos en clientes que compraron ambos.
                """)
        
                top_clientes = df_ventas.groupby(["IdProducto", "IdCliente"])["Cantidad"].sum().reset_index()
                tabla_recom = top_clientes.pivot(index="IdCliente", columns="IdProducto", values="Cantidad").fillna(0)
        
                producto_ids = tabla_recom.columns.tolist()
                producto_nombres = df_productos[df_productos["ID_PRODUCTO"].isin(producto_ids)][["ID_PRODUCTO", "Concepto"]].drop_duplicates()
                producto_opciones = producto_nombres.set_index("Concepto").to_dict()["ID_PRODUCTO"]
        
                producto_nombre_sel = st.selectbox("Seleccion√° un producto:", list(producto_opciones.keys()))
                producto_id_sel = producto_opciones[producto_nombre_sel]
        
                model_knn = NearestNeighbors(metric="cosine", algorithm="brute")
                model_knn.fit(tabla_recom.T.values)
        
                index = producto_ids.index(producto_id_sel)
                distancias, indices = model_knn.kneighbors([tabla_recom.T.values[index]], n_neighbors=6)
        
                st.write("### Productos recomendados:")
                for i in range(1, len(indices[0])):
                    prod_id = producto_ids[indices[0][i]]
                    descripcion = df_productos[df_productos["ID_PRODUCTO"] == prod_id]["Concepto"].values
                    st.markdown(f"- {descripcion[0] if len(descripcion) else prod_id} (similaridad: {1 - distancias[0][i]:.2f})")
        
            elif submenu == "üìà Predicci√≥n temporal de ventas":
                st.markdown("#### üìà Predicci√≥n de ventas futuras por producto (ARIMA)")
                st.markdown("""
                Este an√°lisis muestra la evoluci√≥n hist√≥rica de las ventas de un producto y proyecta su comportamiento
                para los pr√≥ximos 6 meses utilizando un modelo ARIMA.
                """)
        
                # Merge para traer nombres de productos
                df_ventas = df_ventas.merge(df_productos, left_on="IdProducto", right_on="ID_PRODUCTO", how="left")
                productos_disp = df_ventas[["IdProducto", "Concepto"]].drop_duplicates()
        
                producto_nombre = st.selectbox("Seleccion√° un producto:", productos_disp["Concepto"].tolist())
                producto_id = productos_disp[productos_disp["Concepto"] == producto_nombre]["IdProducto"].values[0]
        
                df_producto = df_ventas[df_ventas["IdProducto"] == producto_id]
                df_ts = df_producto.groupby("Fecha")["Cantidad"].sum().resample("M").sum().dropna()
        
                st.line_chart(df_ts)
        
                try:
                    model = sm.tsa.ARIMA(df_ts, order=(1, 1, 1))
                    results = model.fit()
                    forecast = results.forecast(steps=6)
        
                    st.markdown("#### üìä Predicci√≥n para los pr√≥ximos 6 meses")
                    st.line_chart(forecast)
                except Exception as e:
                    st.error(f"‚ùå Error al generar el modelo ARIMA: {e}")

            elif submenu == "üîù Top 10 productos por mes":
                st.markdown("#### üîù Top 10 productos m√°s vendidos por mes")
            
                # Unimos productos para obtener sus nombres
                df_ventas = df_ventas.merge(df_productos, left_on="IdProducto", right_on="ID_PRODUCTO", how="left")
            
                # Extraemos a√±o y mes
                df_ventas["A√±o"] = df_ventas["Fecha"].dt.year
                df_ventas["Mes"] = df_ventas["Fecha"].dt.month
                df_ventas["MesNombre"] = df_ventas["Mes"].apply(lambda x: calendar.month_name[int(x)])
            
                # Filtros a√±o y mes
                a√±os_disponibles = sorted(df_ventas["A√±o"].dropna().unique())
                a√±o_sel = st.selectbox("Seleccion√° un a√±o:", a√±os_disponibles)
            
                meses_disponibles = df_ventas[df_ventas["A√±o"] == a√±o_sel]["MesNombre"].dropna().unique().tolist()
                mes_nombre_sel = st.selectbox("Seleccion√° un mes:", sorted(meses_disponibles, key=lambda x: list(calendar.month_name).index(x)))
                mes_sel = list(calendar.month_name).index(mes_nombre_sel)
            
                # Filtrar por a√±o y mes
                df_filtrado = df_ventas[(df_ventas["A√±o"] == a√±o_sel) & (df_ventas["Mes"] == mes_sel)]
            
                # TOP 10 productos m√°s vendidos
                top10 = df_filtrado.groupby("Concepto")["Cantidad"].sum().sort_values(ascending=False).head(10).reset_index()
            
                st.markdown("##### üìä Top 10 productos m√°s vendidos")
                st.dataframe(top10)
            
                # Dispersi√≥n de todos los productos clasificados
                st.markdown("##### üìà Dispersi√≥n de productos (clasificados por cantidad vendida)")
            
                resumen = df_filtrado.groupby("Concepto")["Cantidad"].sum().reset_index()
                promedio = resumen["Cantidad"].mean()
            
                def clasificar(cantidad):
                    if cantidad > promedio:
                        return "M√°s vendidos"
                    elif cantidad < promedio:
                        return "Menos vendidos"
                    else:
                        return "Promedio"
            
                resumen["Clasificaci√≥n"] = resumen["Cantidad"].apply(clasificar)
            
                import plotly.express as px
                fig = px.scatter(
                    resumen,
                    x="Concepto",
                    y="Cantidad",
                    color="Clasificaci√≥n",
                    title=f"Dispersi√≥n de ventas por producto - {mes_nombre_sel} {a√±o_sel}",
                    labels={"Cantidad": "Cantidad Vendida", "Concepto": "Producto"}
                )
                fig.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig)


####################
        ## Proveedores
        ##############
        elif categoria == "üöö Proveedores":
                    st.subheader("üöö Proveedores")
                
                    submenu = st.radio("Seleccion√° el tipo de an√°lisis:", [
                        "üí∞ Top 10 proveedores por gasto",
                    ])
            
        elif submenu == "üí∞ Top 10 proveedores por gasto":
        st.markdown("#### üí∞ Top 10 proveedores por monto total de compra")
    
        @st.cache_data
        def load_compras():
            return pd.read_csv("Compra_transformada.csv", parse_dates=["Fecha"])
    
        @st.cache_data
        def load_proveedores():
            return pd.read_csv("Proveedores_transformado.csv")
    
        df_compras = load_compras()
        df_prov = load_proveedores()
    
        # üîß Unir el nombre del proveedor correctamente
        df = df_compras.merge(df_prov, left_on="IdProveedor", right_on="IDProveedor", how="left")
    
        # üßÆ Calcular top 10 por monto total
        top10_prov = df.groupby("Nombre")["Monto"].sum().sort_values(ascending=False).head(10).reset_index()
        st.markdown("##### üìã Tabla: Top 10 proveedores por monto total")
        st.dataframe(top10_prov)
    
        st.markdown("##### üìà Evoluci√≥n mensual del gasto por proveedor")
    
        # üìÖ Agrupar por mes
        df["Mes"] = df["Fecha"].dt.to_period("M").dt.to_timestamp()
        gasto_mensual = df.groupby(["Mes", "Nombre"])["Monto"].sum().reset_index()
    
        # üîç Filtro de selecci√≥n m√∫ltiple
        proveedores_disp = top10_prov["Nombre"].tolist()
        proveedores_sel = st.multiselect(
            "Seleccion√° uno o m√°s proveedores:",
            options=proveedores_disp,
            default=proveedores_disp[:3]
        )
    
        # üìä Gr√°fico
        import plotly.express as px
        fig = px.line(
            gasto_mensual[gasto_mensual["Nombre"].isin(proveedores_sel)],
            x="Mes", y="Monto", color="Nombre",
            labels={"Monto": "Monto de compra", "Mes": "Mes", "Nombre": "Proveedor"},
            title="Evoluci√≥n mensual del gasto por proveedor"
        )
        fig.update_layout(xaxis_title="Mes", yaxis_title="Monto total")
        st.plotly_chart(fig)

        

    
################
#### MAPA ######
################

    
    elif menu == "Mapa de sucursales y empleados":
        st.header("üó∫Ô∏è Mapa de sucursales y empleados")
    
        # Cargar los datos
        sucursales_df = pd.read_csv("Sucursales_transformado.csv")
        ventas_df = pd.read_csv("Venta_transformado.csv")
        empleados_df = pd.read_csv("Empleados_transformados.csv")
        productos_df = pd.read_csv("PRODUCTOS_transformado.csv")
    
        # Limpiar columnas
        sucursales_df.columns = sucursales_df.columns.str.strip()
        empleados_df.columns = empleados_df.columns.str.strip()
        ventas_df.columns = ventas_df.columns.str.strip()
    
        # Selector de sucursales
        sucursal_seleccionada = st.selectbox("Selecciona una sucursal", ["Todas"] + list(sucursales_df["Sucursal"].unique()))
    
        # Crear mapa base
        mapa = folium.Map(location=[sucursales_df["Latitud"].mean(), sucursales_df["Longitud"].mean()], zoom_start=5)
    
        if sucursal_seleccionada == "Todas":
            for _, row in sucursales_df.iterrows():
                folium.Marker([row["Latitud"], row["Longitud"]], popup=row["Sucursal"]).add_to(mapa)
        else:
            row = sucursales_df[sucursales_df["Sucursal"] == sucursal_seleccionada].iloc[0]
            folium.Marker([row["Latitud"], row["Longitud"]], popup=row["Sucursal"]).add_to(mapa)
    
        st_folium(mapa, width=700, height=500)
    
        # Empleados por sucursal
        st.subheader("üëî Empleados por sucursal")
        empleados_por_sucursal = empleados_df.groupby("Sucursal")["ID_empleado"].count().reset_index()
        st.bar_chart(empleados_por_sucursal.set_index("Sucursal"))
    
        if sucursal_seleccionada != "Todas":
            st.subheader(f"üë• Empleados en {sucursal_seleccionada}")
            empleados_sucursal = empleados_df[empleados_df["Sucursal"] == sucursal_seleccionada]
            st.dataframe(empleados_sucursal[["Nombre", "Apellido", "Cargo"]])
    
            if not empleados_sucursal.empty:
                empleado_seleccionado = st.selectbox("Selecciona un empleado", empleados_sucursal["Nombre"].unique())
    
                # Procesamiento de ventas
                ventas_df["Fecha"] = pd.to_datetime(ventas_df["Fecha"], errors="coerce")
                ventas_df = ventas_df[ventas_df["Fecha"] >= "2015-01-01"]
                ventas_df["Ventas_totales"] = ventas_df["Precio"] * ventas_df["Cantidad"]
    
                # Agrupaci√≥n de ventas por empleado
                resumen_ventas = ventas_df.groupby("IdEmpleado")["Ventas_totales"].sum().reset_index()
                resumen_ventas = resumen_ventas.merge(empleados_df, left_on="IdEmpleado", right_on="ID_empleado", how="left")
    
                ventas_filtradas = resumen_ventas[
                    (resumen_ventas["Sucursal"] == sucursal_seleccionada) &
                    (resumen_ventas["Nombre"] == empleado_seleccionado)
                ]
    
                st.subheader(f"üìà Ventas de {empleado_seleccionado} desde 2015")
                st.write(ventas_filtradas[["Nombre", "Apellido", "Ventas_totales"]])

                # Gr√°fico
                fig = px.bar(ventas_filtradas, x="Nombre", y="Ventas_totales", color="Sucursal",
                             title=f"Ventas de {empleado_seleccionado} en {sucursal_seleccionada}")
                st.plotly_chart(fig)
    
                # Comparaci√≥n de ventas totales por empleado
                st.subheader("Comparaci√≥n de ventas por empleado")
                empleado_comparar = st.selectbox("Selecciona otro empleado para comparar", empleados_sucursal["Nombre"].unique())
        
                ventas_df["Ventas_totales"] = ventas_df["Precio"] * ventas_df["Cantidad"]
        
                ventas_empleados = ventas_df.merge(empleados_df, left_on="IdEmpleado", right_on="ID_empleado", how="left")
                ventas_filtradas = ventas_empleados[
                    (ventas_empleados["Sucursal"] == sucursal_seleccionada) &
                    (ventas_empleados["Nombre"].isin([empleado_seleccionado, empleado_comparar]))
                ]
        
                resumen_comparativo = ventas_filtradas.groupby("Nombre")["Ventas_totales"].sum().reset_index()
        
                fig = px.bar(resumen_comparativo, x="Nombre", y="Ventas_totales", color="Nombre",
                             title=f"Comparaci√≥n de ventas totales en {sucursal_seleccionada}")
        
                st.plotly_chart(fig)

                # Comparaci√≥n de todos los empleados de la sucursal
                st.subheader("Ventas por empleado en la sucursal")
                ventas_sucursal = ventas_empleados[ventas_empleados["Sucursal"] == sucursal_seleccionada]
                resumen_sucursal = ventas_sucursal.groupby("Nombre")["Ventas_totales"].sum().reset_index().sort_values(by="Ventas_totales", ascending=False)
        
                fig_all = px.bar(resumen_sucursal, x="Nombre", y="Ventas_totales", color="Nombre",
                                 title=f"Ventas totales por empleado en {sucursal_seleccionada}")
                st.plotly_chart(fig_all)
        
    else:
        st.warning("üîí Ingres√° la clave correcta para acceder a la app")
